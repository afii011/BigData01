{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c25d6f",
   "metadata": {
    "id": "10c25d6f"
   },
   "source": [
    "# Hands-On Pertemuan 1: Pengenalan Big Data dan Overview Teknologi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117dfdb",
   "metadata": {
    "id": "7117dfdb"
   },
   "source": [
    "## Tujuan\n",
    "Pada akhir praktikum ini, mahasiswa diharapkan mampu:\n",
    "1. Memahami konsep dasar Big Data.\n",
    "2. Menjelaskan karakteristik dan tantangan Big Data (Volume, Variety, Velocity, dan Veracity).\n",
    "3. Mengenal teknologi yang digunakan dalam ekosistem Big Data.\n",
    "4. Menginstal dan mengonfigurasi Anaconda untuk bekerja dengan alat Big Data seperti Hadoop dan Spark.\n",
    "5. Memulai praktik sederhana terkait pengolahan data menggunakan PySpark dan Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e805141",
   "metadata": {
    "id": "7e805141"
   },
   "source": [
    "## Peralatan yang Dibutuhkan\n",
    "1. Anaconda (untuk manajemen lingkungan)\n",
    "2. Jupyter Notebook (bawaan dari Anaconda)\n",
    "3. PySpark (untuk pemrosesan data skala besar)\n",
    "4. Pandas (untuk data analysis)\n",
    "5. Python (bawaan dari Anaconda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3xmH7-KgH-TH",
   "metadata": {
    "id": "3xmH7-KgH-TH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8daa78a0",
   "metadata": {
    "id": "8daa78a0"
   },
   "source": [
    "## Langkah-Langkah Hands-On"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b963c0",
   "metadata": {
    "id": "23b963c0"
   },
   "source": [
    "### 1. Instalasi Anaconda\n",
    "- **Langkah 1: Unduh dan Instal Anaconda**\n",
    "  Anaconda adalah platform distribusi Python yang menyertakan berbagai alat pengembangan, termasuk Jupyter Notebook. Ikuti langkah-langkah instalasi sesuai sistem operasi:\n",
    "  - Unduh Anaconda: [Download Anaconda](https://www.anaconda.com/products/individual)\n",
    "  - Instal sesuai instruksi yang ada di situs web tersebut (Windows/Mac/Linux).\n",
    "\n",
    "- **Langkah 2: Menginstal PySpark di Anaconda**\n",
    "  Setelah Anaconda terinstal, tambahkan PySpark:\n",
    "  ```bash\n",
    "  pip install pyspark==3.4.1\n",
    "  ```\n",
    "\n",
    "- **Langkah 3: Menginstal Pandas**\n",
    "  Untuk memudahkan data analysis, install Pandas:\n",
    "  ```bash\n",
    "  pip install pandas\n",
    "  ```\n",
    "\n",
    "- **Langkah 4: Menginstal Findspark**\n",
    "  ```bash\n",
    "  pip install findspark\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f1a45",
   "metadata": {
    "id": "208f1a45"
   },
   "source": [
    "### 2. Pengenalan dan Praktik Dasar PySpark dan Pandas\n",
    "- **Langkah 1: Membuka Jupyter Notebook**\n",
    "  Setelah instalasi selesai, buka Jupyter Notebook melalui Anaconda Navigator atau melalui terminal dengan perintah:\n",
    "  ```bash\n",
    "  jupyter notebook\n",
    "  ```\n",
    "\n",
    "- **Langkah 2: Membuat Project Notebook Baru**\n",
    "  Di Jupyter Notebook, buat notebook baru untuk praktikum ini.\n",
    "\n",
    "- **Langkah 3: Praktik dengan PySpark**\n",
    "  Buat program sederhana untuk memulai dengan PySpark. Gunakan PySpark untuk membuat DataFrame dan memanipulasi data sederhana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "KERSZShIH_aN",
   "metadata": {
    "id": "KERSZShIH_aN"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747276f",
   "metadata": {
    "id": "8747276f"
   },
   "source": [
    "- **Tugas 1**: Jalankan kode di atas dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78a5053",
   "metadata": {
    "id": "f78a5053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------------+------------------+------+\n",
      "| Nama|Usia|       Pekerjaan|              Hobi|Gender|\n",
      "+-----+----+----------------+------------------+------+\n",
      "|  Ali|  34|    Pengangguran|        Menganggur|     L|\n",
      "| Budi|  23|            Guru|          Diskotik|     L|\n",
      "|Citra|  29|            Chef| Collect phonecase|     P|\n",
      "| Dina|  45|Ibu Rumah Tangga|Nonton drama India|     P|\n",
      "+-----+----+----------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34, \"Pengangguran\", \"Menganggur\", \"L\"), (\"Budi\", 23, \"Guru\", \"Diskotik\", \"L\"), (\"Citra\", 29, \"Chef\", \"Collect phonecase\", \"P\"), (\"Dina\", 45, \"Ibu Rumah Tangga\", \"Nonton drama India\", \"P\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84a333",
   "metadata": {
    "id": "1f84a333"
   },
   "source": [
    "### 3. Praktik PySpark Lanjutan\n",
    "- **Latihan 1**: Memanipulasi Data dengan PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06767bc",
   "metadata": {
    "id": "e06767bc"
   },
   "source": [
    "- **Tugas 2**: Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f391ed5",
   "metadata": {
    "id": "1f391ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n",
      "+----+----+\n",
      "|Nama|Usia|\n",
      "+----+----+\n",
      "| Ali|  34|\n",
      "|Dina|  45|\n",
      "+----+----+\n",
      "\n",
      "+---------+\n",
      "|avg(Usia)|\n",
      "+---------+\n",
      "|    32.75|\n",
      "+---------+\n",
      "\n",
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "|  Ali|  34|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()\n",
    "\n",
    "# Filtering data\n",
    "df_filtered = df.filter(df['Usia'] > 30)\n",
    "df_filtered.show()\n",
    "\n",
    "# Menghitung rata-rata usia\n",
    "from pyspark.sql.functions import avg\n",
    "df.groupBy().agg(avg(\"Usia\")).show()\n",
    "\n",
    "# Mengurutkan data berdasarkan usia\n",
    "df_sorted = df.orderBy(\"Usia\", ascending=True)\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e34a5",
   "metadata": {
    "id": "fe1e34a5"
   },
   "source": [
    "### 4. Praktik dengan Pandas\n",
    "- **Latihan 2**:  Buat DataFrame menggunakan Pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da455f1",
   "metadata": {
    "id": "9da455f1"
   },
   "source": [
    "- **Tugas 3**: Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1f2ec1",
   "metadata": {
    "id": "3f1f2ec1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Usia</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>34</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budi</td>\n",
       "      <td>23</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citra</td>\n",
       "      <td>29</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dina</td>\n",
       "      <td>45</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nama  Usia Gender\n",
       "0    Ali    34      L\n",
       "1   Budi    23      L\n",
       "2  Citra    29      P\n",
       "3   Dina    45      P"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45], \n",
    "               \"Gender\": [\"L\", \"L\", \"P\", \"P\"]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menampilkan DataFrame Pandas\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0042b2b",
   "metadata": {
    "id": "c0042b2b"
   },
   "source": [
    "### 5. Praktik Pandas Lanjutan\n",
    "- **Latihan 3**: Penggunaan Pandas untuk operasi lebih kompleks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a8142f",
   "metadata": {
    "id": "e7a8142f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Pekerjaan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>Dokter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budi</td>\n",
       "      <td>Guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citra</td>\n",
       "      <td>Insinyur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dina</td>\n",
       "      <td>Perawat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nama Pekerjaan\n",
       "0    Ali    Dokter\n",
       "1   Budi      Guru\n",
       "2  Citra  Insinyur\n",
       "3   Dina   Perawat"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame kedua\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "df_pandas_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ed75d",
   "metadata": {
    "id": "884ed75d"
   },
   "source": [
    "- **Tugas 4**: Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2afb5481-1278-4a70-bcc5-f78e1f3647af",
   "metadata": {
    "id": "e7a8142f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Nama  Usia Pekerjaan\n",
      "0    Ali    34    Dokter\n",
      "1   Budi    23      Guru\n",
      "2  Citra    29  Insinyur\n",
      "3   Dina    45   Perawat\n",
      "            Usia\n",
      "count   4.000000\n",
      "mean   32.750000\n",
      "std     9.322911\n",
      "min    23.000000\n",
      "25%    27.500000\n",
      "50%    31.500000\n",
      "75%    36.750000\n",
      "max    45.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame kedua\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \n",
    "                 \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Join antara dua DataFrame\n",
    "df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\")\n",
    "print(df_joined)\n",
    "\n",
    "# Menghitung statistik deskriptif\n",
    "print(df_pandas.describe())\n",
    "\n",
    "# Plotting Data\n",
    "import matplotlib.pyplot as plt\n",
    "df_pandas['Usia'].plot(kind='bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf671ba3",
   "metadata": {
    "id": "bf671ba3"
   },
   "source": [
    "### 5. Menggabungkan PySpark dan Pandas\n",
    "- **Latihan 4: Mengonversi DataFrame antara PySpark dan Pandas**\n",
    "  Praktik untuk convert DataFrame dari PySpark ke Pandas dan sebaliknya:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "337e123f",
   "metadata": {
    "id": "337e123f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Nama  Usia\n",
       " 0    Ali    34\n",
       " 1   Budi    23\n",
       " 2  Citra    29\n",
       " 3   Dina    45,\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "df_pandas_from_spark, df_spark_from_pandas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba4e5c",
   "metadata": {
    "id": "2cba4e5c"
   },
   "source": [
    "- **Tugas 5**: Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6459816b-a5ad-43bb-9845-834e60feafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "| Gema|  18|\n",
      "|Rizqi|  58|\n",
      "|Mulia|  34|\n",
      "|Akbar|  21|\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n",
      "+---------+\n",
      "|avg(Usia)|\n",
      "+---------+\n",
      "|    32.75|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Memulai Spark Session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Gema\", \"Rizqi\", \"Mulia\", \"Akbar\"], \n",
    "               \"Usia\": [18, 58, 34, 21]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Menggabungkan DataFrame konversi PySpark to Pandas dan Pandas\n",
    "df_joined = pd.concat([df_pandas, df_pandas_from_spark], ignore_index=True)\n",
    "\n",
    "# Mengonversi hasil gabungan DataFrame Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_joined)\n",
    "df_spark_from_pandas.show()\n",
    "\n",
    "# Menghitung rata-rata usia\n",
    "df_spark_from_pandas.groupBy().agg(avg(\"Usia\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdba6be",
   "metadata": {
    "id": "afdba6be"
   },
   "source": [
    "### 6. Konversi Data antara PySpark dan Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a490a29-6806-4d9e-9838-beab6d372402",
   "metadata": {
    "id": "f863defc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "| Gema|  18|\n",
      "|Rizqi|  58|\n",
      "|Mulia|  34|\n",
      "|Akbar|  21|\n",
      "+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Nama  Usia\n",
       " 0    Ali    34\n",
       " 1   Budi    23\n",
       " 2  Citra    29\n",
       " 3   Dina    45,\n",
       " None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "df_pandas_from_spark, df_spark_from_pandas.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65adbe71",
   "metadata": {
    "id": "65adbe71"
   },
   "source": [
    "- **Tugas 6**: Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0484cb34-1f7f-48f5-97dd-dabfa937e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "| Gema|  18|\n",
      "|Rizqi|  58|\n",
      "|Mulia|  34|\n",
      "|Akbar|  21|\n",
      "+-----+----+\n",
      "\n",
      "+---------+\n",
      "|max(Usia)|\n",
      "+---------+\n",
      "|       58|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max  # Importing max function for aggregation\n",
    "\n",
    "# Memulai Spark Session\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana di PySpark\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "data_pandas = {\"Nama\": [\"Gema\", \"Rizqi\", \"Mulia\", \"Akbar\"], \n",
    "               \"Usia\": [18, 58, 34, 21]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menggabungkan DataFrame dari PySpark dan Pandas\n",
    "df_combined = df.union(df_spark_from_pandas)  # Using union to combine DataFrames\n",
    "\n",
    "# Menampilkan DataFrame hasil gabungan\n",
    "df_combined.show()\n",
    "\n",
    "# Menghitung nilai maksimum usia\n",
    "df_combined.agg(max(\"Usia\")).show()  # Calculate maximum age"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
